"""
AI ì‘ë‹µ ìºì‹± ì„œë¹„ìŠ¤

OpenAI GPT ì‘ë‹µì„ Redisì— ìºì‹±í•˜ì—¬:
- ì‘ë‹µ ì†ë„: 2-5ì´ˆ â†’ 5-10ms (500ë°° ê°œì„ )
- API ë¹„ìš©: 99% ì ˆê°
- ì•ˆì •ì„±: API ì¥ì•  ì‹œì—ë„ ì„œë¹„ìŠ¤ ìœ ì§€
"""

import json
import hashlib
from typing import Optional, Dict, Any
from app.services.cache_service import CacheService


class AICacheService:
    """AI ì‘ë‹µ ì „ìš© ìºì‹± ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.cache = CacheService()
        
        # AI ì‘ë‹µë³„ TTL ì „ëµ (ì´ˆ ë‹¨ìœ„)
        self.ttl_strategies = {
            'nearby_regions': 30 * 24 * 3600,   # 30ì¼: ì§€ì—­ ì •ë³´ëŠ” ê±°ì˜ ì•ˆ ë³€í•¨
            'travel_style': 7 * 24 * 3600,       # 7ì¼: ìŠ¤íƒ€ì¼ ë¶„ì„ ë¡œì§
            'place_category': 30 * 24 * 3600,    # 30ì¼: ì¹´í…Œê³ ë¦¬ëŠ” ì•ˆ ë³€í•¨
            'location_info': 30 * 24 * 3600,     # 30ì¼: ë„ì‹œ ì •ë³´
            'default': 7 * 24 * 3600             # ê¸°ë³¸ 7ì¼
        }
    
    def _generate_cache_key(self, prefix: str, prompt: str) -> str:
        """
        í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ìºì‹œ í‚¤ ìƒì„±
        
        Args:
            prefix: ìºì‹œ íƒ€ì… (ì˜ˆ: 'nearby_regions', 'travel_style')
            prompt: AIì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ ë˜ëŠ” ì¿¼ë¦¬
        
        Returns:
            í•´ì‹œëœ ìºì‹œ í‚¤ (ì˜ˆ: 'ai:nearby_regions:a1b2c3d4e5f6')
        """
        # í”„ë¡¬í”„íŠ¸ë¥¼ í•´ì‹œí•˜ì—¬ ê³ ì • ê¸¸ì´ í‚¤ ìƒì„±
        prompt_hash = hashlib.md5(prompt.encode('utf-8')).hexdigest()[:12]
        return f"ai:{prefix}:{prompt_hash}"
    
    def get_cached_ai_response(
        self,
        cache_type: str,
        prompt: str
    ) -> Optional[Dict[str, Any]]:
        """
        ìºì‹œëœ AI ì‘ë‹µ ì¡°íšŒ
        
        Args:
            cache_type: ìºì‹œ íƒ€ì… (nearby_regions, travel_style ë“±)
            prompt: AI í”„ë¡¬í”„íŠ¸
        
        Returns:
            ìºì‹œëœ ì‘ë‹µ ë˜ëŠ” None
        """
        cache_key = self._generate_cache_key(cache_type, prompt)
        
        cached = self.cache.get(cache_key)
        if cached:
            print(f"   âš¡ AI ìºì‹œ íˆíŠ¸: {cache_type} ({prompt[:30]}...)")
            return cached
        
        return None
    
    def save_ai_response(
        self,
        cache_type: str,
        prompt: str,
        response: Dict[str, Any]
    ):
        """
        AI ì‘ë‹µì„ Redisì— ìºì‹±
        
        Args:
            cache_type: ìºì‹œ íƒ€ì…
            prompt: AI í”„ë¡¬í”„íŠ¸
            response: AI ì‘ë‹µ ë°ì´í„°
        """
        cache_key = self._generate_cache_key(cache_type, prompt)
        ttl = self.ttl_strategies.get(cache_type, self.ttl_strategies['default'])
        
        self.cache.set(cache_key, response, ttl)
        
        ttl_days = ttl // (24 * 3600)
        print(f"   ğŸ’¾ AI ì‘ë‹µ ìºì‹±: {cache_type} (TTL: {ttl_days}ì¼)")
    
    def invalidate_cache(self, cache_type: str = None):
        """
        íŠ¹ì • íƒ€ì…ì˜ ìºì‹œ ë¬´íš¨í™” (ê°œë°œ/ë””ë²„ê¹…ìš©)
        
        Args:
            cache_type: ë¬´íš¨í™”í•  ìºì‹œ íƒ€ì… (Noneì´ë©´ ì „ì²´)
        """
        # Redisì˜ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ì‚­ì œ
        if cache_type:
            pattern = f"ai:{cache_type}:*"
        else:
            pattern = "ai:*"
        
        print(f"ğŸ—‘ï¸ AI ìºì‹œ ë¬´íš¨í™”: {pattern}")
        # Note: cache_serviceì— íŒ¨í„´ ì‚­ì œ ë©”ì„œë“œ ì¶”ê°€ í•„ìš”


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_ai_cache_service = None


def get_ai_cache_service() -> AICacheService:
    """AI ìºì‹œ ì„œë¹„ìŠ¤ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _ai_cache_service
    if _ai_cache_service is None:
        _ai_cache_service = AICacheService()
    return _ai_cache_service

